# -*- coding: utf-8 -*-
"""olmazsaEskisi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L3yRXS0f4MidHsSVYisfxcjQ9oRlL3vb
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier

df = pd.read_csv("malicious_dataset_with_10000_benign.csv")

df = df[df["type"] != "type"]

df["type"] = df["type"].str.strip()

df["label"] = df["type"].apply(lambda x: 0 if x == "benign" else 1)

plt.figure(figsize=(8, 4))
sns.countplot(data=df, x="type", order=df["type"].value_counts().index)
plt.title("Sınıf Dağılımı")
plt.show()

print(df["type"].value_counts())

df["label"] = df["type"].apply(lambda x: 0 if x == "benign" else 1)

X = df["url"]
y = df["label"]

vectorizer = TfidfVectorizer(
    max_features=10000, 
    min_df=5,            
    max_df=0.8,          
    token_pattern=r'[a-zA-Z0-9]{2,}'  
)
X_vect = vectorizer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_vect, y, test_size=0.2, random_state=42, stratify=y
)

model = XGBClassifier(
    tree_method="gpu_hist",  
    use_label_encoder=False,
    eval_metric="logloss",
    random_state=42,
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=(y == 0).sum() / (y == 1).sum()  
)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

#Özellik çıkarma işlemi
def extract_features(df):
    df_feat = pd.DataFrame()
    df_feat["url_length"] = df["url"].apply(len)
    df_feat["num_digits"] = df["url"].str.count(r'\d')
    df_feat["num_special_chars"] = df["url"].str.count(r'[^\w]')
    df_feat["has_https"] = df["url"].str.contains("https").astype(int)
    df_feat["num_subdomains"] = df["url"].str.count(r'\.')
    return df_feat

from scipy.sparse import hstack

X_tfidf = vectorizer.fit_transform(X)
X_extra = extract_features(df)
X_combined = hstack([X_tfidf, X_extra.values])

X_train, X_test, y_train, y_test = train_test_split(
    X_combined, y, test_size=0.2, random_state=42, stratify=y
)

model = XGBClassifier(
    tree_method="gpu_hist",
    use_label_encoder=False,
    eval_metric="logloss",
    n_estimators=300,
    max_depth=8,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),
    random_state=42
)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(
    n_estimators=200,
    max_depth=20,
    class_weight="balanced",
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

import joblib

joblib.dump(model, "xgb_url_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")
joblib.dump(X_extra.columns.tolist(), "extra_feature_names.pkl")

import gradio as gr
import joblib
import re
import pandas as pd
from scipy.sparse import hstack


model = joblib.load("xgb_url_model.pkl")
vectorizer = joblib.load("tfidf_vectorizer.pkl")
extra_features = joblib.load("extra_feature_names.pkl")

def extract_features_from_url(url):
    return pd.DataFrame([{
        "url_length": len(url),
        "num_digits": len(re.findall(r'\d', url)),
        "num_special_chars": len(re.findall(r'[^\w]', url)),
        "has_https": int("https" in url),
        "num_subdomains": url.count('.')
    }])[extra_features]

def predict_url_with_proba(url):
    url_tfidf = vectorizer.transform([url])
    url_extra = extract_features_from_url(url)
    combined_features = hstack([url_tfidf, url_extra.values])

    prediction = model.predict(combined_features)[0]
    probability = model.predict_proba(combined_features)[0][prediction]

    label = "Güvenli (Benign)" if prediction == 0 else "Zararlı (Malicious)"
    confidence = f"%{round(probability * 100, 2)} güven"

    return f"{label} - {confidence}"

gr.Interface(
    fn=predict_url_with_proba,
    inputs=gr.Textbox(label="URL'yi girin"),
    outputs=gr.Textbox(label="Tahmin Sonucu"),
    title="URL Güvenlik Tahmin Aracı",
    description="URL'yi analiz eder ve güvenli (benign) mi yoksa zararlı (malicious) mı olduğunu tahmin eder. Doğruluk oranı ile birlikte sonuç verir.",
    theme="default"
).launch(share=True)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(6, 4))
sns.countplot(data=df, x="type", order=df["type"].value_counts().index, palette="viridis")
plt.title("Sınıf Dağılımı (Veri Dengesi)")
plt.xlabel("Sınıf (type)")
plt.ylabel("Adet")
plt.xticks(rotation=20)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Benign", "Malicious"])
disp.plot(cmap="Blues")
plt.title("XGBoost - Confusion Matrix")
plt.show()

from sklearn.metrics import roc_curve, auc

y_prob = model.predict_proba(X_test)[:, 1]  # XGBoost için
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'XGBoost ROC (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Eğrisi')
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np

feature_names = vectorizer.get_feature_names_out()
importances = model.feature_importances_

nonzero_indices = np.where(importances > 0)[0]
top_n = min(20, len(nonzero_indices)) 

sorted_indices = np.argsort(importances[nonzero_indices])[-top_n:]
selected_indices = nonzero_indices[sorted_indices]

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
bars = plt.barh(range(top_n), importances[selected_indices], align="center", color="skyblue")



plt.xlabel("Önem Skoru")
plt.title("XGBoost – En Önemli Kelimeler (TF-IDF Özellikleri)")

for i, bar in enumerate(bars):
    score = importances[selected_indices[i]]
    plt.text(score + 0.001, i, f"{score:.4f}", va='center', fontsize=9)

plt.gca().invert_yaxis()  
plt.tight_layout()
plt.show()

x = ["XGBoost", "Random Forest"]
y_scores = [
    accuracy_score(y_test, y_pred),
    accuracy_score(y_test, y_pred_rf)
]

plt.figure(figsize=(6, 4))
sns.barplot(x=x, y=y_scores, palette="Set2")
plt.ylim(0, 1)
plt.ylabel("Doğruluk (Accuracy)")
plt.title("Model Karşılaştırması")
plt.tight_layout()
plt.show()

plt.figure(figsize=(6, 6))
df["type"].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))
plt.title("Sınıf Oranları (Pie Chart)")
plt.ylabel("")
plt.tight_layout()
plt.show()

features = extract_features(df)
features.hist(figsize=(12, 6), bins=30, color='skyblue', edgecolor='black')
plt.suptitle("Ekstra Özelliklerin Dağılımı")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

features["label"] = df["label"]
plt.figure(figsize=(8, 6))
sns.boxplot(x="label", y="url_length", data=features)
plt.title("Benign ve Malicious URL'lerin Uzunluk Karşılaştırması")
plt.xlabel("Etiket (0: Benign, 1: Malicious)")
plt.ylabel("URL Uzunluğu")
plt.show()

from sklearn.metrics import precision_recall_curve

precision, recall, _ = precision_recall_curve(y_test, y_prob)
plt.figure(figsize=(6, 4))
plt.plot(recall, precision, color='darkgreen', lw=2)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Eğrisi')
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

features = extract_features(df)

labels = df["label"]

benign_lengths = features["url_length"][labels == 0]

malicious_lengths = features["url_length"][labels == 1]

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(benign_lengths, bins=30, color='green', alpha=0.7)
plt.title("Güvenli URL Uzunluk Dağılımı")
plt.xlabel("URL Uzunluğu")
plt.ylabel("Frekans")

plt.subplot(1, 2, 2)
plt.hist(malicious_lengths, bins=30, color='red', alpha=0.7)
plt.title("Zararlı URL Uzunluk Dağılımı")
plt.xlabel("URL Uzunluğu")
plt.ylabel("Frekans")

plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
sns.boxplot(x=df["label"], y=features["url_length"], palette=["green", "red"])
plt.xticks([0, 1], ["Güvenli", "Zararlı"])
plt.title("URL Uzunluklarının Sınıflara Göre Dağılımı")
plt.xlabel("Sınıf")
plt.ylabel("URL Uzunluğu")
plt.show()

plt.figure(figsize=(8, 6))
sns.heatmap(features.corr(), annot=True, cmap="YlGnBu")
plt.title("Özellikler Arası Korelasyon Matrisi")
plt.show()

plt.figure(figsize=(6, 6))
df["label"].value_counts().plot.pie(
    labels=["Güvenli", "Zararlı"],
    autopct="%1.1f%%",
    startangle=90,
    colors=["green", "red"]
)
plt.title("Sınıf Dağılımı (Yüzdelik)")
plt.ylabel("")
plt.show()

import warnings
warnings.filterwarnings("ignore")

all_features = extract_features(df)
all_features["label"] = df["label"]

sns.pairplot(all_features.sample(500), hue="label", palette=["green", "red"])
plt.suptitle("Özelliklerin Birbirine Göre Dağılımı", y=1.02)
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Güvenli", "Zararlı"], yticklabels=["Güvenli", "Zararlı"])
plt.title("Confusion Matrix")
plt.xlabel("Tahmin")
plt.ylabel("Gerçek")
plt.show()

